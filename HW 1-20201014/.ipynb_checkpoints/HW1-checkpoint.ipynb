{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoO-oCQXottz"
   },
   "source": [
    "# Homework 1\n",
    "\n",
    "**DUE OCT 19th by 11:59PM**\n",
    "\n",
    "Homework 1 is done in Jupyter Notebook to give you a chance to familiarize yourself to this powerful tool for data analysis. \n",
    "\n",
    "In Jupyter Notebook, codes and texts are executed in cells. Texts are written in Markdown cell, as you can see in the homework instructions below. Codes are written in code cells. Cells are run one at a time. You can change the cell type by navigating to Cell -> Cell Type.\n",
    "\n",
    "There are spaces for you to enter your answers to the questions, either in code or text. Feel free to add more cells if you need (likely).\n",
    "\n",
    "In many parts, some Scikit-learn functions and classes have already been imported to give you leads on what you may need to use. You still need to refer to the Scikit-learn documentation to learn how the classes and methods work. You can use other publicly available libraries and packages if you want, as long as they finish the work. \n",
    "\n",
    "You are expected to turn in a **pdf version** of this notebook with all your **codes, results, and figures**. Make sure the figures and results are visible as you want them to appear in the pdf before turning it in. Please do not modify the instructions as doing so will limit our ability to follow and grade your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QnIt4o0qmGP"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "Increase your familiarity with Github. This problem needs to be finished with a partner. Follow these steps to finish the problem:\n",
    "\n",
    "1.   Create a github account.\n",
    "2.   Create a public repository and push a helloworld.py file.\n",
    "3.   Person $A$ forks Person $B$'s repo and modifies the file, then pushes to their own fork and finally creates a pull request for person B to merge.\n",
    "4.   Person $B$ reviews and merges the pull request.\n",
    "5.   Do the same for $A$ and $B$ reversed.\n",
    "\n",
    "Provide the links to your repo and your partner's repo.\n",
    "https://github.com/luhan68/CS190DD_HW1\n",
    "https://github.com/Listener-Watcher/CS190DD_P1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKgBcjsyott0"
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "In this problem, you will consider solving the least-squared problem in two different approaches, one using Gradient Descent and the other using the formula. After that, you will compare the results you get from both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afphJhGpott1"
   },
   "source": [
    "a) Load the 1-D data and the labels from **'linear_regression.csv'**. The first column contains the data values and the second column contains the labels. Store the data in a variable ***X***. Similarly, store the labels in a variable ***y***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDFz3_7oott1"
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt('linear_regression.csv', dtype='float', delimiter=',', usecols=(0), unpack=True)\n",
    "y = np.loadtxt('linear_regression.csv', dtype='float', delimiter=',', usecols=(1), unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SVBu5DHott3"
   },
   "source": [
    "b) Fit a linear regression model, in the form $Ax + b$, using the formula. Print out the parameters $A$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Fy8FHUHott4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljnZQZS6ott5"
   },
   "source": [
    "Visualize your result in a 2-D plot. Your plot should show the data points and the line $Ax + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ayp0_6aott6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j45fNRvUott8"
   },
   "source": [
    "c) Now, fit a linear regression model using Gradient Descent. Print out the parameters $A$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yeBTn96ott8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFyYnKvLott-"
   },
   "source": [
    "Visualize your result in a 2-D plot similar to that in part **b**. Compare your results from both parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv2sHAXVott-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJjfeIAuotuA"
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "In this problem, you will train classifiers using two widely used algorithms, Support Vector Machine (SVM) and Random Forest (RF). You will train and fine-tune each model using cross-validation (CV). After that, you will compare the performance of SVM and RF for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34BoVBR3otuA"
   },
   "source": [
    "a) A 13-D dataset with labels is given in **'wine.csv'**. The last column contains the labels. Store the data and the labels in variables ***X*** and ***y***, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRn_EaZqotuB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhA84qMtotuD"
   },
   "source": [
    "Split the data into a train set and a test set. The size of the train set is 90% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-rLDnz2otuD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzmsEV8HotuF"
   },
   "source": [
    "b) Find a good SVM model by performing 10-fold CV on the train set. Try different set of model parameters and record the resulting model performance during CV. Print out your best model's parameters and its performance (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkOVB_IKotuF"
   },
   "outputs": [],
   "source": [
    "# A few methods to get you started with CV. \n",
    "# You are encouraged to look into the model_selection module of Scikit-learn to find tools that best fit your need.\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QftYtzFW-i0E"
   },
   "source": [
    "Now train your best SVM model on the whole train dataset and test it on the test set. Print out your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qCn-sLV_Zhc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTsl_Cc8otuH"
   },
   "source": [
    "c) Similarly, find a good RF model by performing 10-fold CV on the train set. Print out your best model's parameters and its performance (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzWFF9MvotuH"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mfjPPRK_do8"
   },
   "source": [
    "Test your best RF model on the test set. Print out your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35f4P7h2_w61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMWu3IBStbRq"
   },
   "source": [
    "d) Compare the 2 models. Why do we need CV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uac965pmotuL"
   },
   "source": [
    "## Problem 4 (moved to HW 2)\n",
    "\n",
    "In this problem, you will work on the clustering problem using Bottom-up Agglomerative clustering and K-mean clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYox5r6IotuL"
   },
   "source": [
    "a) A 4-D dataset is given in **'iris.csv'** with the last column being the ground truth label. Load the file. Store the data in a variable ***X*** and store the label in a variable ***y***. Because clustering is an unsupervised task, there is no need for the labels during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf0fueP1otuM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzQL_DImotuN"
   },
   "source": [
    "b) Train a clustering model using Bottom-up Agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r90ogg-FotuO"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsr5q1nFotuP"
   },
   "source": [
    "Visualize your clusters on a 2-D plot. Choose any 2 dimensions from the 4 dimensions to plot. Try to pick the 2 dimensions that best separate the data. Your plot should contains all the data points with points from the same predicted cluster haveing the same color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5gBODR5otuQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iEBekEy1SIK"
   },
   "source": [
    "Repeat the visualization step above using the same 2 dimensions. This time, plot according to the ground truth classes. Comment on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3lf0Xrv1w6X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9PfTf2sotuR"
   },
   "source": [
    "c) Train a clustering model using K-mean clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5qzh74NotuR"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htqJKZCrotuT"
   },
   "source": [
    "Visualize your clusters on a 2-D plot. Choose any 2 dimensions from the 4 dimensions to plot. Try to pick the 2 dimensions that best separate the data. Your plot should contains all the data points with points from the same predicted cluster haveing the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deWqhR4potuT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da9qg3Wi1358"
   },
   "source": [
    "Repeat the visualization step above using the same 2 dimensions. This time, plot according to the ground truth classes. Comment on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7EgKmxx17_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-8WjIaNotuV"
   },
   "source": [
    "d) Perform Principle Component Analysis (PCA) on the data. Project the original data on the 2 largest principle components. Store this new projected 2-D data in a variable ***X_projected***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jnx5i9NwotuV"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4VFnvdTotuW"
   },
   "source": [
    "Repeat part **b** on the new 2-D data. Train the Bottom-up Agglomerative model and visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLhLTY-PotuX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhXg9gKEotuY"
   },
   "source": [
    "Repeat part **c** on the new 2-D data. Train the K-means model and visualize your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8jwbAElotuZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz5Wc_dgotua"
   },
   "source": [
    "Compare the quality of 4-D and 2-D clusterings. When would the ideas of projection and dimensionality reduction be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmsQa5XEHUau"
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "What is the hypothesis space for problems 1-3? What are the pros and cons of having a large hypothesis space? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYuqFx8xHa1M"
   },
   "source": [
    "## Problem 6\n",
    "\n",
    "Suppose we find the best binary classifier for a set of red points and another binary classifier for a set of blue points. Now, suppose we are given a new set of $R$ red and $B$ blue points that we can predict to be positive or negative. If we have to choose a subset of $k$ positive points from $R$ union $B$, what would be fair way for choosing. \n",
    "\n",
    "You are given a red dataset in 'R.csv' and a blue dataset in 'B.csv'. There is also a third test dataset in 'RBtest.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFV_vm-orpDp"
   },
   "source": [
    "a) Load the datasets. All datasets are 2-D with the last column containing the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZBjsepYHf5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RemkSEnPr1IB"
   },
   "source": [
    "b) Train 2 classifiers, one for the red dataset and the other for the blue dataset. You are free to choose the learning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFuY0Y8qsNh-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRp8Q1g6sQZW"
   },
   "source": [
    "c) Now use your models to classify instances in the test dataset. The models may agree on many points but may also disagree on many other points. Let's call the set of positive points classified by the red model $P_r$ and the set of positive points classified by the blue model $P_b$. You are asked to pick out $k$ points from the set $P_r \\cup P_b$. What is a fair way to do this. Demonstrate your answer with code and visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INVo2ChrtSOm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
